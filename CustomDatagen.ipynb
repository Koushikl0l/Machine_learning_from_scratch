{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9f298-556c-4302-a3f2-9dadec4852e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, Image_batch,Question_batch,Answer_label_batch, batch_size, dim=(224,224),\n",
    "                 n_classes=1260, path=\"\",shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        #self.n_channels = n_channels\n",
    "        self.indexes = np.arange(len(y))\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.Image_batch = Image_batch\n",
    "        self.Question_batch = Question_batch\n",
    "        self.Answer_label_batch = Answer_label_batch\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Qstn = self.Question_batch[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        IMG = self.Image_batch[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        Ans = self.Answer_label_batch[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        qstn = np.asarray([self.__get_question_(que) for que in Qstn])\n",
    "        img = np.asarray([self.__get_Image_(colab_path+path) for path in IMG])\n",
    "        ans = np.asarray([self.__get_output(c) for c in Ans])\n",
    "       \n",
    "        return tuple([img, qstn]), ans\n",
    "\n",
    "    def __get_question_(self, que):\n",
    "    \n",
    "        #que_arr = (pad_sequences(t.texts_to_sequences([X_que]), maxlen=22, padding='post'))[0]\n",
    "        sequences = tokenizer.texts_to_sequences(que)\n",
    "        sequence_padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "        return sequence_padded\n",
    "\n",
    "    def __get_Image_(self, path):\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        #resize image as (224,224,3)\n",
    "        resized_img = cv.resize(img,self.dim)\n",
    "        #normalize inage\n",
    "        img = np.array(resized_img)/255.0\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def __get_output(self, answer):\n",
    "        return tf.keras.utils.to_categorical(answer, num_classes=self.n_classes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1b547-1848-47ec-9932-695560175780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen_aug(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, X_que, X_img, y,\n",
    "                 batch_size,\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.X_que = X_que\n",
    "        self.X_img = X_img\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(y))\n",
    "        self.vocab_size = 10000\n",
    "        self.embedding_dim = 256\n",
    "        self.max_length = 22\n",
    "        self.trunc_type='post'\n",
    "        self.padding_type='post'\n",
    "        self.oov_tok = \"<OOV>\"\n",
    "        tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(question_list_train)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n",
    "    \n",
    "    def __get_input1(self, que):\n",
    "    \n",
    "        #que_arr = (pad_sequences(t.texts_to_sequences([X_que]), maxlen=22, padding='post'))[0]\n",
    "        training_sequences = tokenizer.texts_to_sequences(que)\n",
    "        training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "        return training_padded\n",
    "\n",
    "    def __get_input2(self, path):\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        # a = np.random.uniform()\n",
    "        # if a<0.25:\n",
    "        #     img = aug1.augment_image(img)\n",
    "        # elif a<0.5:\n",
    "        #     img = aug2.augment_image(img)\n",
    "        # elif a<0.75:\n",
    "        #     img = aug3.augment_image(img)\n",
    "        # else:\n",
    "        #     img = img\n",
    "        img = cv2.resize()    \n",
    "        img = np.array(img)/255.0\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    def __get_output(self, label):\n",
    "        return tf.keras.utils.to_categorical(label, num_classes=1000)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        batch_x0 = self.X_que[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x1 = self.X_img[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        X0_batch = np.asarray([self.__get_input1(que) for que in batch_x0])\n",
    "        X1_batch = np.asarray([self.__get_input2(colab_path+path) for path in batch_x1])\n",
    "        y_batch = np.asarray([self.__get_output(c) for c in batch_y])\n",
    "       \n",
    "        return tuple([X0_batch, X1_batch]), y_batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a7c5d-1cc4-4824-82f5-c354ba5b67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from my_classes import DataGenerator\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (32,32,32),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 6,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "partition = # IDs\n",
    "labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "# Design model\n",
    "model = Sequential()\n",
    "[...] # Architecture\n",
    "model.compile()\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616c074-6c65-45fc-895a-491b2440e822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9ab9e-52f3-4fc7-9376-b927ed38be93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
